{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9809459,"sourceType":"datasetVersion","datasetId":6013179}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Important Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom typing import List, Dict\nfrom dataclasses import dataclass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Loading Dataset","metadata":{}},{"cell_type":"code","source":"file_path = \"/kaggle/input/sub-arxiv/sub_arxiv_subset.csv\"\n\n# reading csv file\ndataset = pd.read_csv(file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# basic info about dataset\nprint(dataset.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cleaning Markdown","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass CleaningStats:\n    equations_removed: int\n    citations_cleaned: int\n    tables_found: int\n    figures_found: int\n    latex_commands_cleaned: int\n    references_removed: int\n\n\nclass AcademicPaperCleaner:\n    def __init__(self):\n        self.inline_equation = r'\\$[^$]+\\$'\n        self.block_equation = r'\\$\\$[^$]+\\$\\$'\n        self.latex_command = r'\\\\[a-zA-Z]+\\{[^}]*\\}'\n        self.citation = r'\\[[\\d,\\s]+\\]'\n        self.reference = r'\\\\cite\\{[^}]*\\}|\\\\citep\\{[^}]*\\}|\\\\citet\\{[^}]*\\}'\n        self.table_start = r'\\\\begin\\{table\\}'\n        self.table_end = r'\\\\end\\{table\\}'\n        self.figure_pattern = r'\\\\includegraphics(\\[.*?\\])?\\{.*?\\}'\n        self.stats = CleaningStats(0, 0, 0, 0, 0, 0)\n\n    def clean_equations(self, text):\n        inline_matches = re.findall(self.inline_equation, text)\n        self.stats.equations_removed += len(inline_matches)\n        text = re.sub(self.inline_equation, '[EQUATION]', text)\n        \n        block_matches = re.findall(self.block_equation, text)\n        self.stats.equations_removed += len(block_matches)\n        text = re.sub(self.block_equation, '[BLOCK_EQUATION]', text)\n        \n        return text\n\n    def clean_citations(self, text):\n        citation_matches = re.findall(self.citation, text)\n        self.stats.citations_cleaned += len(citation_matches)\n        text = re.sub(self.citation, '[REF]', text)\n        return text\n\n    def clean_references(self, text):\n        reference_matches = re.findall(self.reference, text)\n        self.stats.references_removed += len(reference_matches)\n        text = re.sub(self.reference, '', text)\n        return text\n\n    def handle_tables(self, text):\n        table_pattern = f\"{self.table_start}.*?{self.table_end}\"\n        tables = re.findall(table_pattern, text, re.DOTALL)\n        self.stats.tables_found += len(tables)\n        text = re.sub(table_pattern, '[TABLE]', text, flags=re.DOTALL)\n        return text\n\n    def handle_figures(self, text):\n        figure_matches = re.findall(self.figure_pattern, text)\n        self.stats.figures_found += len(figure_matches)\n        text = re.sub(self.figure_pattern, '[FIGURE]', text)\n        return text\n\n    def clean_latex_commands(self, text):\n        command_matches = re.findall(self.latex_command, text)\n        self.stats.latex_commands_cleaned += len(command_matches)\n        text = re.sub(self.latex_command, '', text)\n        return text\n\n    def clean(self, text):\n        text = self.clean_equations(text)\n        text = self.clean_citations(text)\n        text = self.clean_references(text)\n        text = self.handle_tables(text)\n        text = self.handle_figures(text)\n        text = self.clean_latex_commands(text)\n        text = re.sub(r'\\s+', ' ', text).strip()\n        return text\n\n    def get_cleaning_stats(self):\n        return self.stats\n\n    def print_cleaning_stats(self):\n        print(\"Cleaning Statistics:\")\n        print(f\"Equations removed: {self.stats.equations_removed}\")\n        print(f\"Citations cleaned: {self.stats.citations_cleaned}\")\n        print(f\"References removed: {self.stats.references_removed}\")\n        print(f\"Tables found: {self.stats.tables_found}\")\n        print(f\"Figures found: {self.stats.figures_found}\")\n        print(f\"LaTeX commands cleaned: {self.stats.latex_commands_cleaned}\")\n\n\n\n    def clean_dataset(self, dataset):\n        dataset['cleaned_markdown'] = dataset['markdown'].apply(self.clean)\n        return dataset\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\nif __name__ == \"__main__\":\n\n    # Initialize the cleaner\n    cleaner = AcademicPaperCleaner()\n\n    # Clean the dataset\n    cleaned_dataset = cleaner.clean_dataset(dataset)\n\n    # Print the cleaning statistics\n    cleaner.print_cleaning_stats()\n\n    # Save the cleaned dataset\n    cleaned_dataset.to_csv('cleaned_dataset.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CSV Loader","metadata":{}},{"cell_type":"code","source":"import csv\nfrom langchain_community.document_loaders import CSVLoader\n\nclass DatasetLoader:\n    def __init__(self, file_path, content_columns, metadata_columns, delimiter=',', quotechar='\"', field_size_limit=10**6):\n        self.file_path = file_path\n        self.content_columns = content_columns\n        self.metadata_columns = metadata_columns\n        self.delimiter = delimiter\n        self.quotechar = quotechar\n        self.field_size_limit = field_size_limit\n\n    def load_data(self):\n        # Increase the maximum field size limit\n        csv.field_size_limit(self.field_size_limit)\n        \n        # Initialize the CSVLoader with provided arguments\n        loader = CSVLoader(\n            file_path=self.file_path,\n            csv_args={\n                'delimiter': self.delimiter,\n                'quotechar': self.quotechar,\n            },\n            content_columns=self.content_columns,\n            metadata_columns=self.metadata_columns\n        )\n        \n        return loader\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__== \"__main__\":\n    # Example usage\n    dataset_loader = DatasetLoader(\n    file_path=\"/kaggle/working/cleaned_dataset.csv\",\n    content_columns=['markdown'],\n    metadata_columns=['id', 'title', 'authors', 'published_date', 'link']\n)\n\nloader = dataset_loader.load_data()\ndocs = loader.load()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docs = loader.load()\nprint(\"Metadata\")\nprint(docs[0].metadata)\nprint(\"Page Content\")\nprint(docs[0].page_content[:100])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Recursive Split (Chunking)","metadata":{}},{"cell_type":"code","source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\n\nclass TextSplitter:\n    def __init__(self, chunk_size=1500, chunk_overlap=200, length_function=len, is_separator_regex=False):\n        self.chunk_size = chunk_size\n        self.chunk_overlap = chunk_overlap\n        self.length_function = length_function\n        self.is_separator_regex = is_separator_regex\n        self.text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            length_function=self.length_function,\n            is_separator_regex=self.is_separator_regex\n        )\n\n    def split_documents(self, docs):\n        return self.text_splitter.split_documents(docs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__==\"__main__\":\n    # Example usage\n    text_splitter = TextSplitter(chunk_size=1500, chunk_overlap=200)\n    documents = text_splitter.split_documents(docs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(documents[0].page_content)\nprint(documents[0].metadata)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Vector Store","metadata":{}},{"cell_type":"code","source":"from langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain_chroma import Chroma\nfrom tqdm import tqdm\n\nclass VectorStore:\n    def __init__(self, model_name=\"all-MiniLM-L6-v2\", collection_name=\"default_collection\", persist_directory=\"./chroma_db\"):\n        self.model_name = model_name\n        self.collection_name = collection_name\n        self.persist_directory = persist_directory\n\n        # Initialize the embeddings model\n        self.embeddings = HuggingFaceEmbeddings(model_name=self.model_name)\n\n        # Initialize the vector store\n        self.vector_store = Chroma(\n            collection_name=self.collection_name,\n            embedding_function=self.embeddings,\n            persist_directory=self.persist_directory\n        )\n\n    def add_documents(self, documents):\n        \"\"\"\n        Embeds and adds documents to the vector store, with a progress bar.\n        :param documents: A list of LangChain document objects, each with 'page_content' and 'metadata'.\n        \"\"\"\n        # Extract content and metadata from each document\n        texts = [doc.page_content for doc in documents]\n        metadata = [doc.metadata for doc in documents]\n        \n        # Initialize the progress bar\n        with tqdm(total=len(texts), desc=\"Adding documents to vector store\") as pbar:\n            batch_size = 1000  # Adjust batch size as needed\n            for i in range(0, len(texts), batch_size):\n                batch_texts = texts[i:i + batch_size]\n                batch_metadata = metadata[i:i + batch_size]\n                \n                # Add batch to vector store\n                self.vector_store.add_texts(texts=batch_texts, metadatas=batch_metadata)\n                \n                # Update progress bar\n                pbar.update(len(batch_texts))\n\n    def get_vector_store(self):\n        \"\"\"Returns the initialized Chroma vector store.\"\"\"\n        return self.vector_store\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__==\"__main__\":\n    # Example usage\n    vector_store = VectorStore(\n        model_name=\"all-MiniLM-L6-v2\",\n        collection_name=\"arXiv_splits\",\n        persist_directory=\"./chroma_arXiv_db\"\n    )\n\n    # Directly use your list of LangChain documents\n    vector_store.add_documents(documents)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Database Loader","metadata":{}},{"cell_type":"code","source":"from langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\n\nclass DatabaseLoader:\n    def __init__(self, model_name: str, collection_name: str, persist_directory: str):\n        \"\"\"Initialize the DatabaseLoader with the specified model and database settings.\"\"\"\n        self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n        self.collection_name = collection_name\n        self.persist_directory = persist_directory\n        self.db = self.load_database()\n\n    def load_database(self):\n        \"\"\"Load the existing database using the specified embeddings.\"\"\"\n        return Chroma(\n            collection_name=self.collection_name,\n            embedding_function=self.embeddings,\n            persist_directory=self.persist_directory\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:11:29.618420Z","iopub.execute_input":"2024-11-05T11:11:29.618863Z","iopub.status.idle":"2024-11-05T11:11:30.802937Z","shell.execute_reply.started":"2024-11-05T11:11:29.618819Z","shell.execute_reply":"2024-11-05T11:11:30.801893Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if __name__==\"__main__\":\n\n    # Usage\n    db_loader = DatabaseLoader(\n        model_name=\"all-MiniLM-L6-v2\",\n        collection_name=\"arXiv_splits\",\n        persist_directory=\"./chroma_arXiv_db\"\n    )\n    vector_database = db_loader.db","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:11:32.498128Z","iopub.execute_input":"2024-11-05T11:11:32.499276Z","iopub.status.idle":"2024-11-05T11:11:42.097575Z","shell.execute_reply.started":"2024-11-05T11:11:32.499226Z","shell.execute_reply":"2024-11-05T11:11:42.096151Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/tmp/ipykernel_484/3700719820.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n  return Chroma(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Retriever","metadata":{}},{"cell_type":"code","source":"# Initializing vector database\n\nretriever = vector_database.as_retriever(\n    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:11:51.919183Z","iopub.execute_input":"2024-11-05T11:11:51.920013Z","iopub.status.idle":"2024-11-05T11:11:51.926298Z","shell.execute_reply.started":"2024-11-05T11:11:51.919959Z","shell.execute_reply":"2024-11-05T11:11:51.925035Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"retriever.invoke(\"What are the LLMs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:11:53.567887Z","iopub.execute_input":"2024-11-05T11:11:53.569007Z","iopub.status.idle":"2024-11-05T11:11:53.977772Z","shell.execute_reply.started":"2024-11-05T11:11:53.568926Z","shell.execute_reply":"2024-11-05T11:11:53.976500Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'authors': 'Ankita Kakoti, Bichitra Bijay Boruah, Mrinal Kumar Das', 'id': '2301.13552', 'link': 'http://arxiv.org/abs/2301.13552v1', 'published_date': '2023-01-31T11:04:01Z', 'row': 363, 'source': '/kaggle/working/cleaned_dataset.csv', 'title': 'Minimal Left-Right Symmetric Model with $A_4$ modular symmetry'}, page_content='\\\\[<\\\\Delta_{L,R}>=\\\\frac{1}{\\\\sqrt{2}}\\\\begin{pmatrix}0&0\\\\\\\\ v_{L,R}&0\\\\end{pmatrix} \\\\tag{2.5}\\\\]\\n\\n\\\\[<\\\\phi>=\\\\begin{pmatrix}k&0\\\\\\\\ 0&e^{i\\\\theta}k^{\\\\prime}\\\\end{pmatrix} \\\\tag{2.6}\\\\]\\n\\nThe magnitudes of the VEVs follows the relation, \\\\(|v_{L}|^{2}<|k^{2}+{k^{\\\\prime}}^{2}|<|v_{R}|^{2}\\\\). The breaking pattern of the LRSM gauge group takes place in two steps. The LRSM gauge group is first broken down to the Standard Model gauge group by the vev of the scalar triplet \\\\(\\\\Delta_{R}\\\\), and then the Standard Model gauge group is broken down to the electromagnetic gauge group i.e., \\\\(U(1)_{em}\\\\) by the vev of the bidoublet and a tiny vev of the scalar triplet \\\\(\\\\Delta_{L}\\\\).\\n\\nThe Dirac mass terms for the leptons come from the Yukawa Lagrangian, which for the charged leptons and the neutrinos are given by,\\n\\n\\\\[M_{l}=\\\\frac{1}{\\\\sqrt{2}}(k^{\\\\prime}Y_{l}+k\\\\tilde{Y_{l}}) \\\\tag{2.7}\\\\]\\n\\n\\\\[M_{D}=\\\\frac{1}{\\\\sqrt{2}}(kY_{l}+k^{\\\\prime}\\\\tilde{Y_{l}}) \\\\tag{2.8}\\\\]\\n\\nThe light neutrino mass after spontaneous symmetry breaking (SSB), generated within a type (I+II) seesaw can be written as,\\n\\n\\\\[M_{\\\\nu}=M_{\\\\nu}{}^{I}+M_{\\\\nu}{}^{II}, \\\\tag{2.9}\\\\]\\n\\n\\\\[M_{\\\\nu}=M_{D}M_{RR}{}^{-1}M_{D}{}^{T}+M_{LL} \\\\tag{2.10}\\\\]\\nwhere,\\n\\n\\\\[M_{LL}=\\\\sqrt{2}v_{L}f_{L} \\\\tag{11}\\\\]\\n\\nand,\\n\\n\\\\[M_{RR}=\\\\sqrt{2}v_{R}f_{R} \\\\tag{12}\\\\]')]"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Evaluation (code was generated by Claud)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport random\nfrom typing import List, Dict\nimport numpy as np\nfrom tqdm import tqdm\n\ndef create_test_query(title: str) -> str:\n    \"\"\"\n    Use just the title as query for simplicity and reliability\n    \"\"\"\n    return title.strip()\n\ndef load_test_data(file_path: str, n_test_cases: int = 20) -> List[Dict]:\n    \"\"\"\n    Load test cases with more debugging information\n    \"\"\"\n    df = pd.read_csv(file_path)\n    \n    # Randomly select n_test_cases documents\n    test_indices = random.sample(range(len(df)), n_test_cases)\n    \n    test_cases = []\n    for idx in test_indices:\n        query = create_test_query(title=df.loc[idx, 'title'])\n        \n        test_cases.append({\n            'query': query,\n            'title': df.loc[idx, 'title'],\n            'id': str(df.loc[idx, 'id']),  # Convert to string for consistent comparison\n            'index': idx\n        })\n    \n    return test_cases\n\ndef print_retrieval_debug(query: str, relevant_id: str, retrieved_docs, retriever_name: str):\n    \"\"\"\n    Print debugging information for a retrieval attempt\n    \"\"\"\n    print(f\"\\nDEBUG for {retriever_name}\")\n    print(f\"Query: {query}\")\n    print(f\"Expected ID: {relevant_id}\")\n    print(\"\\nRetrieved docs:\")\n    for i, doc in enumerate(retrieved_docs[:5], 1):\n        doc_id = doc.metadata.get('id', 'NO_ID')\n        doc_title = doc.metadata.get('title', 'NO_TITLE')\n        print(f\"{i}. ID: {doc_id} | Title: {doc_title}\")\n    print(\"-\" * 50)\n\ndef calculate_metrics(retrieved_docs, relevant_doc_id: str, k: int = 5, debug: bool = False):\n    \"\"\"\n    Calculate metrics with option for debugging output\n    \"\"\"\n    # Convert retrieved IDs to strings for consistent comparison\n    retrieved_ids = [str(doc.metadata.get('id', '')) for doc in retrieved_docs[:k]]\n    \n    if debug:\n        print(f\"Relevant ID: {relevant_doc_id}\")\n        print(f\"Retrieved IDs: {retrieved_ids}\")\n    \n    metrics = {\n        'hit@k': 0,\n        'mrr': 0,\n        'rank': k + 1\n    }\n    \n    if relevant_doc_id in retrieved_ids:\n        rank = retrieved_ids.index(relevant_doc_id) + 1\n        metrics['hit@k'] = 1\n        metrics['mrr'] = 1.0 / rank\n        metrics['rank'] = rank\n    \n    return metrics\n\ndef evaluate_retriever(text_retriever, test_cases: List[Dict], k: int = 5):\n    \"\"\"\n    Evaluate text retriever with debugging information\n    \"\"\"\n    results = {\n        'text': {'hits': 0, 'mrr': [], 'ranks': [], 'queries': []}\n    }\n    \n    # Print first few retrievals for debugging\n    debug_count = 2  # Number of queries to debug in detail\n    \n    for i, test_case in enumerate(tqdm(test_cases, desc=\"Evaluating text retriever\")):\n        query = test_case['query']\n        relevant_id = test_case['id']\n        \n        debug = (i < debug_count)  # Debug only first few queries\n        \n        # Test text retriever\n        try:\n            text_docs = text_retriever.get_relevant_documents(query)\n            if debug:\n                print_retrieval_debug(query, relevant_id, text_docs, \"Text Retriever\")\n            \n            text_metrics = calculate_metrics(text_docs, relevant_id, k, debug)\n            results['text']['hits'] += text_metrics['hit@k']\n            results['text']['mrr'].append(text_metrics['mrr'])\n            results['text']['ranks'].append(text_metrics['rank'])\n            results['text']['queries'].append({\n                'query': query,\n                'success': text_metrics['hit@k'] == 1\n            })\n        except Exception as e:\n            print(f\"Error in text retriever: {e}\")\n    \n    return results\n\ndef format_results(results: Dict, n_queries: int):\n    \"\"\"\n    Format and print evaluation results\n    \"\"\"\n    print(\"\\nEvaluation Results:\")\n    print(\"-\" * 50)\n    \n    for retriever_name, metrics in results.items():\n        hit_rate = (metrics['hits'] / n_queries) * 100\n        mrr = np.mean(metrics['mrr'])\n        median_rank = np.median(metrics['ranks'])\n        \n        print(f\"\\n{retriever_name.upper()} Retriever:\")\n        print(f\"Hit@5 Rate: {hit_rate:.2f}%\")\n        print(f\"Mean Reciprocal Rank: {mrr:.3f}\")\n        print(f\"Median Rank: {median_rank:.1f}\")\n        \n        # Show some example successful and failed queries\n        successful_queries = [q['query'] for q in metrics['queries'] if q['success']]\n        failed_queries = [q['query'] for q in metrics['queries'] if not q['success']]\n        \n        print(f\"\\nTotal Successful Queries: {len(successful_queries)}\")\n        print(f\"Total Failed Queries: {len(failed_queries)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load test cases\ntest_cases = load_test_data('/kaggle/working/cleaned_dataset.csv', n_test_cases=20)\n\n# Evaluate retrievers\nresults = evaluate_retrievers(retriever, retriever, test_cases, k=5)\n\n# Format and print results\nformat_results(results, n_queries=len(test_cases))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Retriever","metadata":{}},{"cell_type":"code","source":"%pip install langchain_community\n%pip install langchain-chroma\n%pip install -qU langchain-huggingface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T17:08:04.407430Z","iopub.execute_input":"2025-01-06T17:08:04.407840Z","iopub.status.idle":"2025-01-06T17:09:08.998407Z","shell.execute_reply.started":"2025-01-06T17:08:04.407795Z","shell.execute_reply":"2025-01-06T17:09:08.995715Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain_community\n  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nCollecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain<0.4.0,>=0.3.14 (from langchain_community)\n  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\nCollecting langchain-core<0.4.0,>=0.3.29 (from langchain_community)\n  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\nCollecting langsmith<0.3,>=0.1.125 (from langchain_community)\n  Downloading langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nCollecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain<0.4.0,>=0.3.14->langchain_community)\n  Downloading langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.9.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.29->langchain_community)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.4)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.125->langchain_community)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.23.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.0)\nDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.2.10-py3-none-any.whl (326 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.4/326.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\nDownloading langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, httpx-sse, requests-toolbelt, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed httpx-sse-0.4.0 langchain-0.3.14 langchain-core-0.3.29 langchain-text-splitters-0.3.4 langchain_community-0.3.14 langsmith-0.2.10 packaging-24.2 pydantic-settings-2.7.1 requests-toolbelt-1.0.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting langchain-chroma\n  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\nCollecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma)\n  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: fastapi<1,>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from langchain-chroma) (0.111.0)\nRequirement already satisfied: langchain-core<0.4,>=0.1.40 in /opt/conda/lib/python3.10/site-packages (from langchain-chroma) (0.3.29)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-chroma) (1.26.4)\nCollecting build>=1.0.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.9.2)\nCollecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nRequirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.30.1)\nCollecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading posthog-3.7.5-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\nCollecting onnxruntime>=1.14.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.25.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.25.0)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.25.0)\nRequirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.0)\nCollecting pypika>=0.48.9 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.4)\nRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)\nRequirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.64.1)\nCollecting bcrypt>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.12.3)\nCollecting kubernetes>=28.1.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.3.0)\nRequirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.0.2)\nCollecting mmh3>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.4)\nRequirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.27.0)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.7.1)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.37.2)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.0.4)\nRequirement already satisfied: jinja2>=2.11.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.1.4)\nRequirement already satisfied: python-multipart>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.0.9)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (5.10.0)\nRequirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (2.1.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (1.33)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (0.2.10)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (24.2)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.1)\nRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (2.6.1)\nRequirement already satisfied: idna>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.4.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain-chroma) (2.1.5)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1.40->langchain-chroma) (2.4)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.30.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.32.3)\nRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.26.18)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.1.40->langchain-chroma) (1.0.0)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.12)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\nRequirement already satisfied: importlib-metadata<=7.1,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.0.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.63.1)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.25.0)\nRequirement already satisfied: opentelemetry-proto==1.25.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.25.0)\nCollecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\nINFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\nCollecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\nCollecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (70.0.0)\nCollecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.46b0)\nCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.23.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.25.1)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.22.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (12.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.6.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.19.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\nDownloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\nDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\nDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\nDownloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\nDownloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\nDownloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\nDownloading posthog-3.7.5-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\nDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\nDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=9ccfd10f5f93f622410924a4f3be24fbfe28621a0119e531c844c0788d0e4096\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, durationpy, pyproject_hooks, opentelemetry-util-http, mmh3, humanfriendly, chroma-hnswlib, bcrypt, backoff, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n  Attempting uninstall: kubernetes\n    Found existing installation: kubernetes 26.1.0\n    Uninstalling kubernetes-26.1.0:\n      Successfully uninstalled kubernetes-26.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 31.0.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 durationpy-0.9 humanfriendly-10.0 kubernetes-31.0.0 langchain-chroma-0.1.4 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-util-http-0.46b0 posthog-3.7.5 pypika-0.48.9 pyproject_hooks-1.2.0\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}