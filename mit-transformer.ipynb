{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:21.923121Z","iopub.execute_input":"2024-12-31T18:35:21.923451Z","iopub.status.idle":"2024-12-31T18:35:22.877654Z","shell.execute_reply.started":"2024-12-31T18:35:21.923430Z","shell.execute_reply":"2024-12-31T18:35:22.876746Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"datasets.features.image\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:22.884741Z","iopub.execute_input":"2024-12-31T18:35:22.885063Z","iopub.status.idle":"2024-12-31T18:35:22.889485Z","shell.execute_reply.started":"2024-12-31T18:35:22.885029Z","shell.execute_reply":"2024-12-31T18:35:22.888388Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install -q transformers datasets evaluate segments-ai\n# apt-get install git-lfs\n# git lfs install\n# huggingface-cli login","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:22.892697Z","iopub.execute_input":"2024-12-31T18:35:22.892920Z","iopub.status.idle":"2024-12-31T18:35:27.379221Z","shell.execute_reply.started":"2024-12-31T18:35:22.892901Z","shell.execute_reply":"2024-12-31T18:35:27.378116Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import wandb\n\nimport os\nos.environ[\"WANDB_API_KEY\"] = \"9983dd9227c197ed3668a18ae85f138f9968030d\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:27.382146Z","iopub.execute_input":"2024-12-31T18:35:27.382402Z","iopub.status.idle":"2024-12-31T18:35:28.454242Z","shell.execute_reply.started":"2024-12-31T18:35:27.382368Z","shell.execute_reply":"2024-12-31T18:35:28.453609Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Load and Prepare Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nrepo_id = \"mattmdjaga/human_parsing_dataset\"\n\ndataset = load_dataset(repo_id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:28.460158Z","iopub.execute_input":"2024-12-31T18:35:28.460479Z","iopub.status.idle":"2024-12-31T18:35:31.893911Z","shell.execute_reply.started":"2024-12-31T18:35:28.460450Z","shell.execute_reply":"2024-12-31T18:35:31.892415Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Shuffle and Split Dataset","metadata":{}},{"cell_type":"markdown","source":"### Renaming the Dataset Columns","metadata":{}},{"cell_type":"code","source":"dataset = dataset.rename_column('image', 'pixel_values')\ndataset = dataset.rename_column('mask','label')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:31.895309Z","iopub.execute_input":"2024-12-31T18:35:31.895874Z","iopub.status.idle":"2024-12-31T18:35:31.907481Z","shell.execute_reply.started":"2024-12-31T18:35:31.895833Z","shell.execute_reply":"2024-12-31T18:35:31.906597Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset = dataset.shuffle(seed=1)\ndataset = dataset[\"train\"].train_test_split(test_size=0.2)\ntrain_ds = dataset[\"train\"]\ntest_ds = dataset[\"test\"]\n\n# Select the first 100 samples from the train dataset\ntrain_ds = train_ds.select(range(10000))\n\n# Select the first 100 samples from the test dataset\ntest_ds = test_ds.select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:31.908388Z","iopub.execute_input":"2024-12-31T18:35:31.908731Z","iopub.status.idle":"2024-12-31T18:35:32.189876Z","shell.execute_reply.started":"2024-12-31T18:35:31.908697Z","shell.execute_reply":"2024-12-31T18:35:32.189055Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import json\nfrom huggingface_hub import hf_hub_download\n\n# repo_id = f\"datasets/{hf_dataset_identifier}\"\nfilename = \"id2label.json\"\nid2label = json.load(open(hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\"), \"r\"))\nid2label = {int(k): v for k, v in id2label.items()}\nlabel2id = {v: k for k, v in id2label.items()}\n\nnum_labels = len(id2label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:32.190718Z","iopub.execute_input":"2024-12-31T18:35:32.190999Z","iopub.status.idle":"2024-12-31T18:35:32.305256Z","shell.execute_reply.started":"2024-12-31T18:35:32.190974Z","shell.execute_reply":"2024-12-31T18:35:32.304506Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import json\n\n# Pretty-print the JSON content\nprint(\"id2label.json Content:\")\nprint(json.dumps(id2label, indent=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:32.306053Z","iopub.execute_input":"2024-12-31T18:35:32.306374Z","iopub.status.idle":"2024-12-31T18:35:32.311592Z","shell.execute_reply.started":"2024-12-31T18:35:32.306350Z","shell.execute_reply":"2024-12-31T18:35:32.310529Z"}},"outputs":[{"name":"stdout","text":"id2label.json Content:\n{\n    \"0\": \"Background\",\n    \"1\": \"Hat\",\n    \"2\": \"Hair\",\n    \"3\": \"Sunglasses\",\n    \"4\": \"Upper-clothes\",\n    \"5\": \"Skirt\",\n    \"6\": \"Pants\",\n    \"7\": \"Dress\",\n    \"8\": \"Belt\",\n    \"9\": \"Left-shoe\",\n    \"10\": \"Right-shoe\",\n    \"11\": \"Face\",\n    \"12\": \"Left-leg\",\n    \"13\": \"Right-leg\",\n    \"14\": \"Left-arm\",\n    \"15\": \"Right-arm\",\n    \"16\": \"Bag\",\n    \"17\": \"Scarf\"\n}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Image Processor and Data Augmentation","metadata":{}},{"cell_type":"code","source":"from torchvision.transforms import ColorJitter\nfrom transformers import SegformerImageProcessor\n\nprocessor = SegformerImageProcessor()\njitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1) \n\ndef train_transforms(example_batch):\n    images = [jitter(x) for x in example_batch['pixel_values']]\n    labels = [x for x in example_batch['label']]\n    inputs = processor(images, labels)\n    return inputs\n\n\ndef val_transforms(example_batch):\n    images = [x for x in example_batch['pixel_values']]\n    labels = [x for x in example_batch['label']]\n    inputs = processor(images, labels)\n    return inputs\n\n\n# Set transforms\ntrain_ds.set_transform(train_transforms)\ntest_ds.set_transform(val_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:32.312479Z","iopub.execute_input":"2024-12-31T18:35:32.312768Z","iopub.status.idle":"2024-12-31T18:35:45.443710Z","shell.execute_reply.started":"2024-12-31T18:35:32.312734Z","shell.execute_reply":"2024-12-31T18:35:45.442747Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Fine Tune a SegFormer","metadata":{}},{"cell_type":"code","source":"from transformers import SegformerForSemanticSegmentation\nmodel_name=\"/kaggle/working/model_(2)/checkpoint-4000\"\npretrained_model_name = \"nvidia/mit-b0\" \nmodel = SegformerForSemanticSegmentation.from_pretrained(\n    model_name,\n    id2label=id2label,\n    label2id=label2id\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:45.444665Z","iopub.execute_input":"2024-12-31T18:35:45.445205Z","iopub.status.idle":"2024-12-31T18:35:45.806194Z","shell.execute_reply.started":"2024-12-31T18:35:45.445180Z","shell.execute_reply":"2024-12-31T18:35:45.805544Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nepochs = 50\nlr = 0.00006\nbatch_size = 16\n\n\ntraining_args = TrainingArguments(\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    save_total_limit=3,\n    report_to=\"wandb\",  # enable logging to W&B\n    run_name=\"MiT-Sagformer-0\",\n    eval_strategy=\"steps\",\n    save_strategy=\"steps\",\n    save_steps=1000,\n    eval_steps=1000,\n    weight_decay=0.01, \n    logging_steps=1,\n    output_dir=\"/kaggle/working/model_(2)\",\n    eval_accumulation_steps=2,\n    load_best_model_at_end=True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:45.806974Z","iopub.execute_input":"2024-12-31T18:35:45.807180Z","iopub.status.idle":"2024-12-31T18:35:46.241583Z","shell.execute_reply.started":"2024-12-31T18:35:45.807162Z","shell.execute_reply":"2024-12-31T18:35:46.240627Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Evaluation Metric","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport evaluate\n\nmetric = evaluate.load(\"mean_iou\")\n\ndef compute_metrics(eval_pred):\n  with torch.no_grad():\n    logits, labels = eval_pred\n    logits_tensor = torch.from_numpy(logits)\n    # scale the logits to the size of the label\n    logits_tensor = nn.functional.interpolate(\n        logits_tensor,\n        size=labels.shape[-2:],\n        mode=\"bilinear\",\n        align_corners=False,\n    ).argmax(dim=1)\n\n    pred_labels = logits_tensor.detach().cpu().numpy()\n    metrics = metric.compute(\n        predictions=pred_labels,\n        references=labels,\n        num_labels=len(id2label),\n        ignore_index=-1,\n        reduce_labels=processor.do_reduce_labels,\n    )\n    \n    # add per category metrics as individual key-value pairs\n    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n\n    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n    \n    return metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:46.242528Z","iopub.execute_input":"2024-12-31T18:35:46.242776Z","iopub.status.idle":"2024-12-31T18:35:47.220364Z","shell.execute_reply.started":"2024-12-31T18:35:46.242755Z","shell.execute_reply":"2024-12-31T18:35:47.219678Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:47.221177Z","iopub.execute_input":"2024-12-31T18:35:47.221896Z","iopub.status.idle":"2024-12-31T18:35:48.023518Z","shell.execute_reply.started":"2024-12-31T18:35:47.221860Z","shell.execute_reply":"2024-12-31T18:35:48.022794Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:35:48.024247Z","iopub.execute_input":"2024-12-31T18:35:48.024515Z","execution_failed":"2024-12-31T23:54:52.864Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msayedhanan\u001b[0m (\u001b[33msayedhanan-virtual-university-of-pakistan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241231_183555-3s3g55hp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sayedhanan-virtual-university-of-pakistan/huggingface/runs/3s3g55hp' target=\"_blank\">MiT-Sagformer-0</a></strong> to <a href='https://wandb.ai/sayedhanan-virtual-university-of-pakistan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sayedhanan-virtual-university-of-pakistan/huggingface' target=\"_blank\">https://wandb.ai/sayedhanan-virtual-university-of-pakistan/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sayedhanan-virtual-university-of-pakistan/huggingface/runs/3s3g55hp' target=\"_blank\">https://wandb.ai/sayedhanan-virtual-university-of-pakistan/huggingface/runs/3s3g55hp</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8383' max='15650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 8383/15650 5:18:44 < 4:36:22, 0.44 it/s, Epoch 26.78/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mean Iou</th>\n      <th>Mean Accuracy</th>\n      <th>Overall Accuracy</th>\n      <th>Accuracy Background</th>\n      <th>Accuracy Hat</th>\n      <th>Accuracy Hair</th>\n      <th>Accuracy Sunglasses</th>\n      <th>Accuracy Upper-clothes</th>\n      <th>Accuracy Skirt</th>\n      <th>Accuracy Pants</th>\n      <th>Accuracy Dress</th>\n      <th>Accuracy Belt</th>\n      <th>Accuracy Left-shoe</th>\n      <th>Accuracy Right-shoe</th>\n      <th>Accuracy Face</th>\n      <th>Accuracy Left-leg</th>\n      <th>Accuracy Right-leg</th>\n      <th>Accuracy Left-arm</th>\n      <th>Accuracy Right-arm</th>\n      <th>Accuracy Bag</th>\n      <th>Accuracy Scarf</th>\n      <th>Iou Background</th>\n      <th>Iou Hat</th>\n      <th>Iou Hair</th>\n      <th>Iou Sunglasses</th>\n      <th>Iou Upper-clothes</th>\n      <th>Iou Skirt</th>\n      <th>Iou Pants</th>\n      <th>Iou Dress</th>\n      <th>Iou Belt</th>\n      <th>Iou Left-shoe</th>\n      <th>Iou Right-shoe</th>\n      <th>Iou Face</th>\n      <th>Iou Left-leg</th>\n      <th>Iou Right-leg</th>\n      <th>Iou Left-arm</th>\n      <th>Iou Right-arm</th>\n      <th>Iou Bag</th>\n      <th>Iou Scarf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>0.114700</td>\n      <td>0.111936</td>\n      <td>0.698230</td>\n      <td>0.797594</td>\n      <td>0.963880</td>\n      <td>0.989463</td>\n      <td>0.792911</td>\n      <td>0.896427</td>\n      <td>0.654990</td>\n      <td>0.918034</td>\n      <td>0.899057</td>\n      <td>0.913413</td>\n      <td>0.890686</td>\n      <td>0.307133</td>\n      <td>0.705677</td>\n      <td>0.710873</td>\n      <td>0.909403</td>\n      <td>0.832087</td>\n      <td>0.861647</td>\n      <td>0.832224</td>\n      <td>0.849456</td>\n      <td>0.844319</td>\n      <td>0.548884</td>\n      <td>0.982305</td>\n      <td>0.695148</td>\n      <td>0.793873</td>\n      <td>0.545263</td>\n      <td>0.829608</td>\n      <td>0.819215</td>\n      <td>0.844968</td>\n      <td>0.774784</td>\n      <td>0.241525</td>\n      <td>0.548830</td>\n      <td>0.557239</td>\n      <td>0.820955</td>\n      <td>0.732723</td>\n      <td>0.745141</td>\n      <td>0.712466</td>\n      <td>0.719046</td>\n      <td>0.723843</td>\n      <td>0.481216</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.103400</td>\n      <td>0.114878</td>\n      <td>0.694927</td>\n      <td>0.798868</td>\n      <td>0.963595</td>\n      <td>0.990030</td>\n      <td>0.798873</td>\n      <td>0.897977</td>\n      <td>0.663286</td>\n      <td>0.901628</td>\n      <td>0.921087</td>\n      <td>0.918703</td>\n      <td>0.883312</td>\n      <td>0.332959</td>\n      <td>0.711832</td>\n      <td>0.721291</td>\n      <td>0.917153</td>\n      <td>0.826420</td>\n      <td>0.859873</td>\n      <td>0.835391</td>\n      <td>0.859391</td>\n      <td>0.830948</td>\n      <td>0.509464</td>\n      <td>0.982401</td>\n      <td>0.686852</td>\n      <td>0.793755</td>\n      <td>0.548919</td>\n      <td>0.829725</td>\n      <td>0.822763</td>\n      <td>0.840993</td>\n      <td>0.770175</td>\n      <td>0.255029</td>\n      <td>0.545886</td>\n      <td>0.556385</td>\n      <td>0.819194</td>\n      <td>0.721697</td>\n      <td>0.734552</td>\n      <td>0.714116</td>\n      <td>0.719422</td>\n      <td>0.721060</td>\n      <td>0.445756</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.125300</td>\n      <td>0.114571</td>\n      <td>0.697498</td>\n      <td>0.796754</td>\n      <td>0.963645</td>\n      <td>0.990283</td>\n      <td>0.812957</td>\n      <td>0.895693</td>\n      <td>0.643852</td>\n      <td>0.920236</td>\n      <td>0.886792</td>\n      <td>0.914694</td>\n      <td>0.870817</td>\n      <td>0.347248</td>\n      <td>0.693176</td>\n      <td>0.707506</td>\n      <td>0.906612</td>\n      <td>0.833168</td>\n      <td>0.850855</td>\n      <td>0.823352</td>\n      <td>0.830130</td>\n      <td>0.851712</td>\n      <td>0.562495</td>\n      <td>0.982595</td>\n      <td>0.691010</td>\n      <td>0.795270</td>\n      <td>0.544408</td>\n      <td>0.828381</td>\n      <td>0.805371</td>\n      <td>0.840632</td>\n      <td>0.764230</td>\n      <td>0.269055</td>\n      <td>0.554967</td>\n      <td>0.564978</td>\n      <td>0.822223</td>\n      <td>0.726568</td>\n      <td>0.741139</td>\n      <td>0.717719</td>\n      <td>0.723643</td>\n      <td>0.724506</td>\n      <td>0.458264</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.074500</td>\n      <td>0.119346</td>\n      <td>0.697802</td>\n      <td>0.797206</td>\n      <td>0.963539</td>\n      <td>0.990622</td>\n      <td>0.783743</td>\n      <td>0.899836</td>\n      <td>0.662328</td>\n      <td>0.927238</td>\n      <td>0.887360</td>\n      <td>0.923021</td>\n      <td>0.821516</td>\n      <td>0.400057</td>\n      <td>0.670312</td>\n      <td>0.727449</td>\n      <td>0.910022</td>\n      <td>0.845996</td>\n      <td>0.856304</td>\n      <td>0.831416</td>\n      <td>0.859884</td>\n      <td>0.843441</td>\n      <td>0.509171</td>\n      <td>0.982600</td>\n      <td>0.688957</td>\n      <td>0.796632</td>\n      <td>0.554907</td>\n      <td>0.827092</td>\n      <td>0.800248</td>\n      <td>0.841903</td>\n      <td>0.757662</td>\n      <td>0.286001</td>\n      <td>0.547251</td>\n      <td>0.570056</td>\n      <td>0.824527</td>\n      <td>0.726680</td>\n      <td>0.736791</td>\n      <td>0.716550</td>\n      <td>0.724751</td>\n      <td>0.725879</td>\n      <td>0.451941</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.080800</td>\n      <td>0.121473</td>\n      <td>0.694101</td>\n      <td>0.793134</td>\n      <td>0.962817</td>\n      <td>0.990110</td>\n      <td>0.802762</td>\n      <td>0.908075</td>\n      <td>0.660610</td>\n      <td>0.918940</td>\n      <td>0.899837</td>\n      <td>0.924400</td>\n      <td>0.830866</td>\n      <td>0.369882</td>\n      <td>0.700784</td>\n      <td>0.702719</td>\n      <td>0.897545</td>\n      <td>0.842678</td>\n      <td>0.839821</td>\n      <td>0.841857</td>\n      <td>0.829960</td>\n      <td>0.841156</td>\n      <td>0.474405</td>\n      <td>0.982709</td>\n      <td>0.688710</td>\n      <td>0.796920</td>\n      <td>0.555324</td>\n      <td>0.823708</td>\n      <td>0.785071</td>\n      <td>0.838908</td>\n      <td>0.737559</td>\n      <td>0.279086</td>\n      <td>0.552232</td>\n      <td>0.560727</td>\n      <td>0.825458</td>\n      <td>0.734270</td>\n      <td>0.744752</td>\n      <td>0.713940</td>\n      <td>0.726624</td>\n      <td>0.725664</td>\n      <td>0.422149</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.099100</td>\n      <td>0.121702</td>\n      <td>0.701752</td>\n      <td>0.802259</td>\n      <td>0.963898</td>\n      <td>0.990900</td>\n      <td>0.790988</td>\n      <td>0.895143</td>\n      <td>0.650452</td>\n      <td>0.910867</td>\n      <td>0.907743</td>\n      <td>0.906644</td>\n      <td>0.858971</td>\n      <td>0.396961</td>\n      <td>0.699470</td>\n      <td>0.710068</td>\n      <td>0.913379</td>\n      <td>0.857187</td>\n      <td>0.848813</td>\n      <td>0.845468</td>\n      <td>0.847116</td>\n      <td>0.859427</td>\n      <td>0.551072</td>\n      <td>0.982706</td>\n      <td>0.690744</td>\n      <td>0.798754</td>\n      <td>0.551839</td>\n      <td>0.831115</td>\n      <td>0.801318</td>\n      <td>0.832900</td>\n      <td>0.765232</td>\n      <td>0.292136</td>\n      <td>0.561831</td>\n      <td>0.571201</td>\n      <td>0.824717</td>\n      <td>0.733158</td>\n      <td>0.747962</td>\n      <td>0.717866</td>\n      <td>0.729278</td>\n      <td>0.722554</td>\n      <td>0.476221</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.081200</td>\n      <td>0.121086</td>\n      <td>0.700042</td>\n      <td>0.798237</td>\n      <td>0.963866</td>\n      <td>0.990567</td>\n      <td>0.793220</td>\n      <td>0.898134</td>\n      <td>0.662586</td>\n      <td>0.916684</td>\n      <td>0.890299</td>\n      <td>0.910994</td>\n      <td>0.872246</td>\n      <td>0.381593</td>\n      <td>0.718547</td>\n      <td>0.714771</td>\n      <td>0.914088</td>\n      <td>0.833693</td>\n      <td>0.855639</td>\n      <td>0.836606</td>\n      <td>0.840838</td>\n      <td>0.839322</td>\n      <td>0.498433</td>\n      <td>0.982760</td>\n      <td>0.695865</td>\n      <td>0.799413</td>\n      <td>0.557482</td>\n      <td>0.831596</td>\n      <td>0.802848</td>\n      <td>0.834479</td>\n      <td>0.760237</td>\n      <td>0.289042</td>\n      <td>0.557459</td>\n      <td>0.566940</td>\n      <td>0.826310</td>\n      <td>0.729740</td>\n      <td>0.748710</td>\n      <td>0.723701</td>\n      <td>0.730471</td>\n      <td>0.725642</td>\n      <td>0.438061</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.092800</td>\n      <td>0.122522</td>\n      <td>0.702641</td>\n      <td>0.801460</td>\n      <td>0.963969</td>\n      <td>0.990390</td>\n      <td>0.792150</td>\n      <td>0.891586</td>\n      <td>0.661262</td>\n      <td>0.916810</td>\n      <td>0.901375</td>\n      <td>0.916268</td>\n      <td>0.867047</td>\n      <td>0.394485</td>\n      <td>0.703521</td>\n      <td>0.711023</td>\n      <td>0.911822</td>\n      <td>0.849053</td>\n      <td>0.848631</td>\n      <td>0.850539</td>\n      <td>0.844153</td>\n      <td>0.841075</td>\n      <td>0.535084</td>\n      <td>0.982825</td>\n      <td>0.687671</td>\n      <td>0.798186</td>\n      <td>0.559816</td>\n      <td>0.829054</td>\n      <td>0.801484</td>\n      <td>0.840137</td>\n      <td>0.758135</td>\n      <td>0.293505</td>\n      <td>0.560666</td>\n      <td>0.570059</td>\n      <td>0.827591</td>\n      <td>0.739182</td>\n      <td>0.751802</td>\n      <td>0.723631</td>\n      <td>0.731213</td>\n      <td>0.729113</td>\n      <td>0.463463</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\nfrom transformers import SegformerImageProcessor\n\nprocessor = SegformerImageProcessor()\nmodel_path = \"/kaggle/working/checkpoint-1000\"\n\n# processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\nmodel = SegformerForSemanticSegmentation.from_pretrained(model_path)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-31T23:54:52.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image = test_ds[5]['pixel_values']\ngt_seg = test_ds[5]['label']","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-31T23:54:52.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-31T23:54:52.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch import nn\n\ninputs = processor(images=image, return_tensors=\"pt\")\noutputs = model(**inputs)\nlogits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n\n# First, rescale logits to original image size\nupsampled_logits = nn.functional.interpolate(\n    logits,\n    size=image.size[::-1], # (height, width)\n    mode='bilinear',\n    align_corners=False\n)\n\n# Second, apply argmax on the class dimension\npred_seg = upsampled_logits.argmax(dim=1)[0]\n","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-31T23:54:52.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(pred_seg)","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-31T23:54:52.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}